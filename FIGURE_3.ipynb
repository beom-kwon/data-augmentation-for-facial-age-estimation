{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97def345-161b-4d2f-be62-de382e274949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "def read_pts(fname):\n",
    "    f = open(fname)\n",
    "    lines = f.readlines()\n",
    "    n_points = int(lines[1].split(':')[1].strip())\n",
    "    \n",
    "    data_lines = lines[3:(n_points+3):1]\n",
    "    points = []\n",
    "    for line in data_lines:\n",
    "        coords = line.strip().split()\n",
    "        points.append(list(map(float, coords)))\n",
    "        \n",
    "    f.close()    \n",
    "    return np.array(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186d3f96-5c25-4770-b931-e8ff92c4507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = [\"./FGNET/images/052A20.JPG\", \"./FGNET/points/052a20.pts\"]\n",
    "\n",
    "face_list, age_list, pid_list = [], [], []\n",
    "\n",
    "img = cv2.imread(path[0], cv2.IMREAD_COLOR)\n",
    "\n",
    "cv2.imshow(\"RGB Image\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf8ab07-7194-41ea-bbdb-91a92d9cdac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(path[0], cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "cv2.imshow(\"Grayscale Image\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097a07b7-5b19-4fba-9a13-6c83486e9a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = read_pts(path[1])\n",
    "\n",
    "point_color = (0, 0, 255)\n",
    "point_radius = 5\n",
    "point_thickness = -1\n",
    "\n",
    "cnt = 0\n",
    "for point in landmarks:\n",
    "    cnt += 1\n",
    "    cv2.circle(img, point.astype(int), point_radius, point_color, point_thickness)\n",
    "\n",
    "cv2.imshow(\"Facial Landmarks\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017af5e7-df36-4433-b5c6-79ac25440910",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(path[0], cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "landmarks = read_pts(path[1])\n",
    "pupils = landmarks[[31, 36], :]\n",
    "\n",
    "cnt = 0\n",
    "for point in pupils:\n",
    "    cnt += 1\n",
    "    cv2.circle(img, point.astype(int), point_radius, point_color, point_thickness)\n",
    "\n",
    "cv2.imshow(\"Before Head Rotation Correction\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64e8b0d-23d7-4bc7-8110-529802a03500",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(path[0], cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "landmarks = read_pts(path[1])\n",
    "pupils = landmarks[[31, 36], :]\n",
    "\n",
    "delta_x, delta_y = pupils[1] - pupils[0]\n",
    "angle = np.arctan(delta_y / delta_x) * 180 / np.pi\n",
    "\n",
    "h, w = img.shape\n",
    "(cx, cy) = (h // 2, w // 2)\n",
    "\n",
    "rotation_matrix = cv2.getRotationMatrix2D(center=(cx, cy), angle=angle, scale=1)\n",
    "img = cv2.warpAffine(img, rotation_matrix, dsize=(img.shape[1], img.shape[0]))\n",
    "\n",
    "landmarks = np.transpose(np.dot(rotation_matrix[:, 0:2], np.transpose(landmarks))) + np.transpose(rotation_matrix[:, 2])\n",
    "pupils = np.transpose(np.dot(rotation_matrix[:, 0:2], np.transpose(pupils))) + np.transpose(rotation_matrix[:, 2])\n",
    "\n",
    "x_min, y_min = np.min(landmarks[:, 0]).astype(int), np.min(landmarks[:, 1]).astype(int)\n",
    "x_max, y_max = np.max(landmarks[:, 0]).astype(int), np.max(landmarks[:, 1]).astype(int)\n",
    "\n",
    "cv2.imshow(\"After Head Rotation Correction\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adbc8a5-fa0e-4158-ba65-a8d0289f7ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(path[0], cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "landmarks = read_pts(path[1])\n",
    "pupils = landmarks[[31, 36], :]\n",
    "\n",
    "delta_x, delta_y = pupils[1] - pupils[0]\n",
    "angle = np.arctan(delta_y / delta_x) * 180 / np.pi\n",
    "\n",
    "h, w = img.shape\n",
    "(cx, cy) = (h // 2, w // 2)\n",
    "\n",
    "rotation_matrix = cv2.getRotationMatrix2D(center=(cx, cy), angle=angle, scale=1)\n",
    "img = cv2.warpAffine(img, rotation_matrix, dsize=(img.shape[1], img.shape[0]))\n",
    "\n",
    "landmarks = np.transpose(np.dot(rotation_matrix[:, 0:2], np.transpose(landmarks))) + np.transpose(rotation_matrix[:, 2])\n",
    "pupils = np.transpose(np.dot(rotation_matrix[:, 0:2], np.transpose(pupils))) + np.transpose(rotation_matrix[:, 2])\n",
    "\n",
    "x_min, y_min = np.min(landmarks[:, 0]).astype(int), np.min(landmarks[:, 1]).astype(int)\n",
    "x_max, y_max = np.max(landmarks[:, 0]).astype(int), np.max(landmarks[:, 1]).astype(int)\n",
    "\n",
    "height = y_max - y_min + 1\n",
    "width = x_max - x_min + 1\n",
    "if height > width:\n",
    "    print(\"case1\")\n",
    "    diff = height - width\n",
    "    pad = diff // 2\n",
    "    img = img[y_min:(y_max + 1), (x_min - pad):(x_max + 1 + (diff - pad))]\n",
    "elif height < width:\n",
    "    print(\"case2\")\n",
    "    diff = width - height\n",
    "    pad = diff // 2\n",
    "    img = img[(y_min - pad):(y_max + 1 + (diff - pad)), x_min:(x_max + 1)]\n",
    "else:\n",
    "    print(\"case3\")\n",
    "    img = img[y_min:(y_max + 1), x_min:(x_max + 1)]\n",
    "\n",
    "cv2.imshow(\"Cropped Image\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55b8fda-5061-4b3f-8fa0-9d2803506ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "img = clahe.apply(img)\n",
    "\n",
    "cv2.imshow(\"CLAHE\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfa5458-bb13-44db-ad0d-9da37868bc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.resize(src=img, dsize=(48, 48), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "cv2.imshow(\"Resized Image\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
